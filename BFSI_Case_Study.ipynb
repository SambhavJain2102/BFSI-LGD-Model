{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134ec749",
   "metadata": {},
   "source": [
    "# Step 1: Business Problem Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd2199",
   "metadata": {},
   "source": [
    "In this case study, we need to build a model that can predict the loss given default (LGD) for defaulted accounts to enhance risk management and compliance with regulatory standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac0a0a6",
   "metadata": {},
   "source": [
    "# Step 2: Define Business Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbedb22b",
   "metadata": {},
   "source": [
    "For this assignment, the business objective is to build a model that can predict the Loss Given Default (LGD) for defaulted accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba49af8",
   "metadata": {},
   "source": [
    "# Step 3: Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries and Warnings.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498df1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option( 'display.max_rows' , 500)\n",
    "pd.set_option( 'display.max_columns' , 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load datasets\n",
    "# main_loan_base = pd.read_csv(\"main_loan_base.csv\")\n",
    "# repayment_base = pd.read_csv(\"repayment_base.csv\")\n",
    "# monthly_balance_base = pd.read_csv(\"monthly_balance_base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab7bba-907b-437a-b81a-3f46bdc4522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "main_loan_base = pd.read_csv('main_loan_base.csv')\n",
    "repayment_base = pd.read_csv('repayment_base.csv')\n",
    "monthly_balance_base = pd.read_csv('monthly_balance_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of dataset and shape\n",
    "print(main_loan_base.shape)\n",
    "main_loan_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdca787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of dataset and shape\n",
    "print(repayment_base.shape)\n",
    "repayment_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of dataset and shape\n",
    "print(monthly_balance_base.shape)\n",
    "monthly_balance_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da110065",
   "metadata": {},
   "source": [
    "# Step 4: Data Cleaning and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4dfec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'repayment_date' column to datetime format\n",
    "repayment_base['repayment_date'] = pd.to_datetime(repayment_base['repayment_date'])\n",
    "\n",
    "# Group by 'loan_acc_num' and sum the repayment amounts\n",
    "repayment_sum_per_loan = repayment_base.groupby('loan_acc_num')['repayment_amount'].sum().reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(repayment_sum_per_loan.shape)\n",
    "repayment_sum_per_loan.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff21851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "monthly_balance_base['date'] = pd.to_datetime(monthly_balance_base['date'])\n",
    "\n",
    "# Find the index of rows with the latest date for each loan_acc_num\n",
    "latest_date_idx = monthly_balance_base.groupby('loan_acc_num')['date'].idxmax()\n",
    "\n",
    "# Select rows with the latest date for each loan_acc_num\n",
    "latest_balance_rows = monthly_balance_base.loc[latest_date_idx]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(latest_balance_rows.shape)\n",
    "latest_balance_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging all datasets together\n",
    "\n",
    "Train_Data = pd.merge(main_loan_base, repayment_sum_per_loan, on='loan_acc_num', how='left')\n",
    "Train_Data = pd.merge(Train_Data, latest_balance_rows, on='loan_acc_num', how='left')\n",
    "\n",
    "print(Train_Data.shape)\n",
    "Train_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99255039",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "#### Creating new column as \"Regular_Payment_Period\" = \"default_date\" - \"disbursal_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 'disbursal_date' and 'default_date' columns to datetime format\n",
    "Train_Data['disbursal_date'] = pd.to_datetime(Train_Data['disbursal_date'])\n",
    "Train_Data['default_date'] = pd.to_datetime(Train_Data['default_date'])\n",
    "\n",
    "# Calculate the number of months between 'disbursal_date' and 'default_date'\n",
    "Train_Data['Regular_Payment_Period'] = (Train_Data['default_date'] - Train_Data['disbursal_date']).dt.days / 30.4375\n",
    "\n",
    "# Round off the values to two decimal places\n",
    "Train_Data['Regular_Payment_Period'] = Train_Data['Regular_Payment_Period'].round(2)\n",
    "# Convert 'tenure_years' column to months\n",
    "Train_Data['tenure_months'] = Train_Data['tenure_years'] * 12\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame with the converted 'Regular_Payment_Period' & Tenure in months column\n",
    "Train_Data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924217d",
   "metadata": {},
   "source": [
    "#### Removing all Date columns as those wont be useful for creating final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "drop_cols = ['disbursal_date', 'default_date', 'date', 'customer_address', 'customer_name','tenure_years']\n",
    "\n",
    "# Drop the columns from Train_Data\n",
    "Train_Data.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(Train_Data.shape)\n",
    "Train_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90cc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d0269",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd512318",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*Train_Data.isnull().mean(),2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in 'repayment_amount' and 'balance_amount' columns with 0\n",
    "Train_Data['repayment_amount'].fillna(0, inplace=True)\n",
    "Train_Data['balance_amount'].fillna(0, inplace=True)\n",
    "\n",
    "round(100*Train_Data.isnull().mean(),2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heads of dataset\n",
    "Train_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c36c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the value_counts of loan_type column\n",
    "Train_Data['loan_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2d42b",
   "metadata": {},
   "source": [
    "### Creating LGD column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Loss Given Default (LGD)\n",
    "Train_Data['LGD'] = Train_Data['loan_amount'] - ((Train_Data['collateral_value'] + Train_Data['repayment_amount']))\n",
    "\n",
    "Train_Data['LGD'] = Train_Data['LGD']/Train_Data['loan_amount']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "Train_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e23941",
   "metadata": {},
   "source": [
    "### EDA\n",
    "Performing Exploratory Data Analysis of Final Data to understand relationship of all variables with Target Variable as \"LGD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of 'loan_type'\n",
    "loan_type_counts = Train_Data['loan_type'].value_counts()\n",
    "\n",
    "# Define colors\n",
    "colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
    "\n",
    "# Plotting a pie chart\n",
    "plt.figure(figsize=(4, 4))  # Set the figure size\n",
    "plt.pie(loan_type_counts, labels=loan_type_counts.index, autopct='%1.1f%%', startangle=180, colors=colors)\n",
    "plt.title('Distribution of Loan Types')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of columns in Train Data\n",
    "Train_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the figure size\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Plot the bar plot for loan_amount\n",
    "ax = sns.barplot(data=Train_Data, x='loan_type', y=Train_Data['loan_amount'] / 1000, color='lightgreen', label='Loan Amount', ci=None)  # ci=None removes error bars\n",
    "\n",
    "# Plot the bar plot for repayment_amount\n",
    "ax = sns.barplot(data=Train_Data, x='loan_type', y=Train_Data['repayment_amount'] / 1000, color='lightcoral', label='Repayment Amount', ci=None)  # ci=None removes error bars\n",
    "\n",
    "# Add data labels to each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=8, color='black', xytext=(0, 5),\n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.title('Loan Amount and Repayment Amount by Loan Type')\n",
    "plt.xlabel('Loan Type')\n",
    "plt.ylabel('Amount (in thousands)')  \n",
    "plt.xticks(rotation=0)  \n",
    "plt.legend() \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fe73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store plots for each loan type\n",
    "loan_type_plots = {}\n",
    "\n",
    "# Define the columns to plot\n",
    "columns_to_plot = ['cheque_bounces', 'missed_repayments', 'number_of_loans']\n",
    "\n",
    "# Define colors for the histograms\n",
    "colors = ['orange', 'salmon', 'lightgreen','crimson']\n",
    "\n",
    "# Iterate over unique loan types\n",
    "for loan_type, color in zip(Train_Data['loan_type'].unique(), colors):\n",
    "    # Filter data for the current loan type\n",
    "    loan_type_data = Train_Data[Train_Data['loan_type'] == loan_type]\n",
    "    \n",
    "    # Create subplots for each column\n",
    "    fig, axes = plt.subplots(len(columns_to_plot), 1, figsize=(12, 3 * len(columns_to_plot)))\n",
    "    \n",
    "    # Plot each column\n",
    "    for i, column in enumerate(columns_to_plot):\n",
    "        # Plot the distribution of the current column\n",
    "        ax = axes[i] if len(columns_to_plot) > 1 else axes\n",
    "        ax.hist(loan_type_data[column], color=color, bins=20, edgecolor='black', linewidth=1.5, alpha=0.7)  # Use plt.hist for histogram\n",
    "        ax.set_title(f'Distribution of {column.replace(\"_\", \" \").title()} for Loan Type: {loan_type}')\n",
    "        ax.set_xlabel(column.replace(\"_\", \" \").title())\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(False) \n",
    "        \n",
    "        # Add labels to each bar\n",
    "        for rect in ax.patches:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2, height + 5, f'{height:.0f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Add distance between bars\n",
    "        ax.margins(x=0.1)\n",
    "    \n",
    "    # Adjust layout of subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'loan_type' and calculate the mean 'LGD' for each group\n",
    "mean_lgd_by_loan_type = Train_Data.groupby('loan_type')['LGD'].mean()\n",
    "\n",
    "# Define color\n",
    "color ='limegreen'\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(6, 4))\n",
    "mean_lgd_by_loan_type.plot(kind='bar', color=color)\n",
    "plt.title('Mean LGD by Loan Type')\n",
    "plt.xlabel('Loan Type')\n",
    "plt.ylabel('Mean LGD')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Add labels to each bar\n",
    "for i, mean_lgd in enumerate(mean_lgd_by_loan_type):\n",
    "    plt.text(i, mean_lgd, f'{mean_lgd:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf7c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store plots for each loan type\n",
    "loan_type_plots = {}\n",
    "\n",
    "# Define the columns to plot\n",
    "columns_to_plot = ['loan_amount', 'collateral_value', 'monthly_emi', 'repayment_amount','balance_amount']\n",
    "\n",
    "# Define colors for the histograms\n",
    "colors = ['limegreen', 'dodgerblue','orchid', 'mediumorchid']\n",
    "\n",
    "# Iterate over unique loan types\n",
    "for loan_type, color in zip(Train_Data['loan_type'].unique(), colors):\n",
    "    # Filter data for the current loan type\n",
    "    loan_type_data = Train_Data[Train_Data['loan_type'] == loan_type]\n",
    "    \n",
    "    # Create subplots for each column\n",
    "    fig, axes = plt.subplots(len(columns_to_plot), 1, figsize=(12, 3 * len(columns_to_plot)))\n",
    "    \n",
    "    # Plot each column\n",
    "    for i, column in enumerate(columns_to_plot):\n",
    "        # Plot the distribution of the current column\n",
    "        ax = axes[i] if len(columns_to_plot) > 1 else axes\n",
    "        ax.hist(loan_type_data[column], color=color, bins=20, edgecolor='black', alpha=0.7)  # Use plt.hist for histogram\n",
    "        ax.set_title(f'Distribution of {column.replace(\"_\", \" \").title()} for Loan Type: {loan_type}')\n",
    "        ax.set_xlabel(column.replace(\"_\", \" \").title())\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(False) \n",
    "        \n",
    "        # Add labels to each bar\n",
    "        for rect in ax.patches:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2, height + 5, f'{height:.0f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Add distance between bars\n",
    "        ax.margins(x=0.1)\n",
    "    \n",
    "    # Adjust layout of subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store plots for each loan type\n",
    "loan_type_plots = {}\n",
    "\n",
    "# Define the columns to plot\n",
    "columns_to_plot = ['vintage_in_months', 'Regular_Payment_Period', 'tenure_months']\n",
    "\n",
    "# Define colors for the histograms\n",
    "colors = ['tomato', 'gold', 'skyblue','teal']\n",
    "\n",
    "# Iterate over unique loan types\n",
    "for loan_type, color in zip(Train_Data['loan_type'].unique(), colors):\n",
    "    # Filter data for the current loan type\n",
    "    loan_type_data = Train_Data[Train_Data['loan_type'] == loan_type]\n",
    "    \n",
    "    # Create subplots for each column\n",
    "    fig, axes = plt.subplots(len(columns_to_plot), 1, figsize=(12, 3 * len(columns_to_plot)))\n",
    "    \n",
    "    # Plot each column\n",
    "    for i, column in enumerate(columns_to_plot):\n",
    "        # Plot the distribution of the current column\n",
    "        ax = axes[i] if len(columns_to_plot) > 1 else axes\n",
    "        ax.hist(loan_type_data[column], color=color, bins=20, edgecolor='black', alpha=0.7)  # Use plt.hist for histogram\n",
    "        ax.set_title(f'Distribution of {column.replace(\"_\", \" \").title()} for Loan Type: {loan_type}')\n",
    "        ax.set_xlabel(column.replace(\"_\", \" \").title())\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(False) \n",
    "        \n",
    "        # Add labels to each bar\n",
    "        for rect in ax.patches:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2, height + 5, f'{height:.0f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Add distance between bars\n",
    "        ax.margins(x=0.1)\n",
    "    \n",
    "    # Adjust layout of subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb841efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store plots for each loan type\n",
    "loan_type_plots = {}\n",
    "\n",
    "# Define the columns to plot\n",
    "columns_to_plot = ['interest']\n",
    "\n",
    "# Define colors for the histograms\n",
    "colors = ['indigo', 'mediumorchid', 'darkorange', 'limegreen', 'tomato', \n",
    "          'skyblue', 'salmon', 'gold', 'teal', 'crimson', 'orchid']\n",
    "\n",
    "# Iterate over unique loan types\n",
    "for loan_type, color in zip(Train_Data['loan_type'].unique(), colors):\n",
    "    # Filter data for the current loan type\n",
    "    loan_type_data = Train_Data[Train_Data['loan_type'] == loan_type]\n",
    "    \n",
    "    # Create subplots for each column\n",
    "    fig, axes = plt.subplots(len(columns_to_plot), 1, figsize=(12, 3 * len(columns_to_plot)))\n",
    "    \n",
    "    # Plot each column\n",
    "    for i, column in enumerate(columns_to_plot):\n",
    "        # Plot the distribution of the current column\n",
    "        ax = axes[i] if len(columns_to_plot) > 1 else axes\n",
    "        ax.hist(loan_type_data[column], color=color, bins=20, edgecolor='black', alpha=0.7)  # Use plt.hist for histogram\n",
    "        ax.set_title(f'Distribution of {column.replace(\"_\", \" \").title()} for Loan Type: {loan_type}')\n",
    "        ax.set_xlabel(column.replace(\"_\", \" \").title())\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(False) \n",
    "        \n",
    "        # Add labels to each bar\n",
    "        for rect in ax.patches:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2, height + 5, f'{height:.0f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Add distance between bars\n",
    "        ax.margins(x=0.1)\n",
    "    \n",
    "    # Adjust layout of subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Heatmap\n",
    "correlation_matrix = Train_Data.corr()\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='mako', center=0)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1caa8-c8bf-4b80-ac96-60736a49ffe3",
   "metadata": {},
   "source": [
    "### As we can see all loan types are equally contributing for the overall distribution,hence, these categorical input variable will have mutli colinearity in model building, Hence deleting this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22858b9c-fbc4-45ef-b52e-1dfa83b8163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = Train_Data.drop([\"loan_type\"], axis=1)\n",
    "Train_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2997c",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Train_Data.drop([\"LGD\"], axis=1)\n",
    "y = Train_Data[\"LGD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e00346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3 , random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee0191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f0ef6f-23ff-4325-a6ed-936b75977050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train\n",
    "X_test_1 = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd10d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "y_train.head().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1048797",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "y_test.head().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop loan_acc_num column\n",
    "X_train = X_train_1.drop('loan_acc_num', axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b005c-7ba7-442b-a8d2-ba6d5a124855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop loan_acc_num column\n",
    "X_test = X_test_1.drop('loan_acc_num', axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924861ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Heatmap\n",
    "correlation_matrix = Train_Data.corr()\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', center=0)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeea3f2-a6b9-4a48-bfa0-cb03d8e15976",
   "metadata": {},
   "source": [
    "### Rescaling the Features\n",
    "### We will use MinMax scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe4ac7-b851-47e6-a740-d6ac4f36b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18bf54-d486-43fa-a721-c4473812a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc6fcd-2587-498a-9ef2-67b2eba99b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "print(X_test.shape)\n",
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843853a8-1dc1-47df-b7aa-1568ddccd8b1",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54483e",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE #RFE (Recursive Feature Elimination)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=12)\n",
    "selector = selector.fit(X_train_scaled, y_train)\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features= list(X_train_scaled.columns[selector.support_])\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_scaled[selected_features]\n",
    "X_test = X_test_scaled[selected_features]\n",
    "print(X_train.head())\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13ac2f-7c11-43fb-a9cb-3afdbc86fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ae8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "X_train_sm=sm.add_constant(X_train) \n",
    "X_test_sm=sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ebb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indices of y_train and X_train_sm\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train_sm.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Fit the OLS model\n",
    "model1 = sm.OLS(y_train, X_train_sm) \n",
    "res1 = model1.fit() \n",
    "res1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627187a8-44a7-48d4-b361-1d02edbb10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data=pd.DataFrame()\n",
    "vif_data[\"Feature\"]=X_train_sm.columns\n",
    "\n",
    "vif_data[\"VIF\"]=[variance_inflation_factor(X_train_sm.values,i) for i in range(len(X_train_sm.columns))]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce49ea-8971-4101-b38c-11f674e0f3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_sm=X_train_sm.drop([\"loan_amount\"],axis=1)\n",
    "X_test_sm=X_test_sm.drop([\"loan_amount\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43cf38-5f2c-45e1-842a-7316b59b1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=sm.OLS(y_train,X_train_sm)\n",
    "res2=model2.fit()\n",
    "res2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b8b18-d820-4554-8b56-30941a6fd8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data=pd.DataFrame()\n",
    "vif_data[\"Feature\"]=X_train_sm.columns\n",
    "vif_data[\"VIF\"]=[variance_inflation_factor(X_train_sm.values,i) for i in range(len(X_train_sm.columns))]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15cd8fb-8668-4f2d-b3b7-fdbad9b5fcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_sm=X_train_sm.drop([\"Regular_Payment_Period\"],axis=1)\n",
    "X_test_sm=X_test_sm.drop([\"Regular_Payment_Period\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d214764d-c22a-47dc-884c-aefc6ae9813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=sm.OLS(y_train,X_train_sm)\n",
    "res3=model3.fit()\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e9813-ded1-4638-a1ad-29c4e39e5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data=pd.DataFrame()\n",
    "vif_data[\"Feature\"]=X_train_sm.columns\n",
    "vif_data[\"VIF\"]=[variance_inflation_factor(X_train_sm.values,i) for i in range(len(X_train_sm.columns))]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13165ce4-b664-481d-a849-672ea45f513a",
   "metadata": {},
   "source": [
    "### Picking up Model-III for performing Residual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2900d5b-b42a-4718-b989-3ce4688ffd0a",
   "metadata": {},
   "source": [
    "### Residual Analysis of the train data\n",
    "\n",
    "So, now to check if the error terms are also normally distributed (which is infact, one of the major assumptions of linear regression), let us plot the histogram of the error terms and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d0b42-06c5-444b-b9e7-6dfa6539f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_1 = res3.predict(X_train_sm)\n",
    "y_train_pred_1.head().reset_index()\n",
    "print(y_train_pred_1.shape)\n",
    "y_train_pred_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fee74-8f62-408f-9fff-9a2284c48629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_pred_1), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 10)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 10)                         # X-label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f019a-7185-4c36-b4a3-d6d6a6c1a20a",
   "metadata": {},
   "source": [
    "#### R^2 Value for Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed4e8f-054e-4207-8653-a944e29b6f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_train, y_train_pred_1)\n",
    "round(r2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad565cb-57de-4d24-a457-564d7f596098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable\n",
    "y_test_pred_1 = res3.predict(X_test_sm)\n",
    "y_test_pred_1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b1aec-7688-42fb-980c-710d45847b05",
   "metadata": {},
   "source": [
    "### Plotting Loan Account number Distribution Plot wrt Predicted Loss Given Default (LGD) Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193f99d-08f9-4c12-b3c3-833fe1e27334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Series to 'LGD'\n",
    "y_test_pred_1 = y_test_pred_1.rename('LGD')\n",
    "\n",
    "# Concatenate the loan account numbers and LGD values along the column axis\n",
    "matched_data_train = pd.concat([X_test_1['loan_acc_num'], y_test_pred_1], axis=1)\n",
    "\n",
    "# Display the matched data\n",
    "matched_data_train['LGD'].value_counts()\n",
    "matched_data_train['loan_acc_num'].unique()\n",
    "X_test_1.shape\n",
    "matched_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64e913-0fd2-42c4-b4f8-02c562dcedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the style of the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot the distribution of LGD values\n",
    "plt.figure(figsize=(20, 8))\n",
    "ax = sns.histplot(matched_data_train['LGD'], kde=True, color='blue')\n",
    "\n",
    "# Add data labels for frequency\n",
    "for rect in ax.patches:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 4, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Distribution of LGD Values')\n",
    "plt.xlabel('LGD')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad54311-a978-47f7-9586-4dee56234049",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed745839-b5ac-4386-8894-e722974dba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f29f0-1325-4a25-b20c-83038fb7c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c078a-7e3a-4a9e-9471-1d2aef2771ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adjusted R^2 Value for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4433ab-1214-4f88-aecc-614b1510629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train_sm.shape[0]\n",
    "# Number of features (predictors, p) is the shape along axis 1\n",
    "p = X_train_sm.shape[1]\n",
    "\n",
    "# We find the Adjusted R-squared using the formula\n",
    "\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "adjusted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca367d7-5733-4aea-b766-2937cca2d373",
   "metadata": {},
   "source": [
    "#### R^2 Value for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dceee2-a2f6-4ada-b13a-c29e09fe4175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_test_pred_1)\n",
    "round(r2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14f955-c0d0-4a9f-b09c-55a3a6fd829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"Test Performance:\",round(r2_score(y_test, y_test_pred_1)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99c5d7-b06b-4563-9e7a-4466bf214827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_test_pred_1), bins=10)  # Specify the number of bins as an integer\n",
    "fig.suptitle('Error Terms', fontsize=10)  # Plot heading\n",
    "plt.xlabel('Errors', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f1707-e19a-4bad-bb3e-2ed7177ffa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb758a88-ee39-4eb6-9d85-15c99194d38e",
   "metadata": {},
   "source": [
    "## Making Predictions on Test Data Provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab3b77-bede-44ce-b342-3be38bbbb081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "main_loan_base_test = pd.read_csv('test_main_loan_base.csv')\n",
    "repayment_base_test = pd.read_csv('test_repayment_base.csv')\n",
    "monthly_balance_base_test = pd.read_csv('test_monthly_balance_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b8ef4-eae4-4c48-a84b-41fa5e419bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(main_loan_base_test.shape)\n",
    "main_loan_base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4d15c-ff6a-466c-9f33-b203098dbcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(repayment_base_test.shape)\n",
    "repayment_base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079f9bd-1363-4ec9-9cbf-5e2b51109053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(monthly_balance_base_test.shape)\n",
    "monthly_balance_base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33317a-9f96-4c52-94cc-6403bdb78833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'repayment_date' column to datetime format\n",
    "repayment_base_test['repayment_date'] = pd.to_datetime(repayment_base_test['repayment_date'])\n",
    "\n",
    "# Group by 'loan_acc_num' and sum the repayment amounts\n",
    "repayment_sum_per_loan_test = repayment_base_test.groupby('loan_acc_num')['repayment_amount'].sum().reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(repayment_sum_per_loan_test.shape)\n",
    "repayment_sum_per_loan_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f4e51-6f10-4316-9a2f-fcba9292d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "monthly_balance_base_test['date'] = pd.to_datetime(monthly_balance_base_test['date'])\n",
    "\n",
    "# Find the index of rows with the latest date for each loan_acc_num\n",
    "latest_date_idx = monthly_balance_base_test.groupby('loan_acc_num')['date'].idxmax()\n",
    "\n",
    "# Select rows with the latest date for each loan_acc_num\n",
    "latest_balance_rows_test = monthly_balance_base_test.loc[latest_date_idx]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(latest_balance_rows_test.shape)\n",
    "latest_balance_rows_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb46363d-fc3b-4178-9638-9d2d7c7e12fb",
   "metadata": {},
   "source": [
    "### Merging all \"TEST\" datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e2044-25e2-4298-87d6-9660c33fe929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Test_Data_1 = pd.merge(main_loan_base_test, repayment_sum_per_loan_test, on='loan_acc_num', how='left')\n",
    "Test_Data_1 = pd.merge(Test_Data_1, latest_balance_rows_test, on='loan_acc_num', how='left')\n",
    "\n",
    "print(Test_Data_1.shape)\n",
    "Test_Data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2a272-2474-4879-b18f-b7c2b0b0e173",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "#### Creating new column as \"Regular_Payment_Period\" = \"default_date\" - \"disbursal_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ee939-d0b8-4923-95f7-4637c4dfdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 'disbursal_date' and 'default_date' columns to datetime format\n",
    "Test_Data_1['disbursal_date'] = pd.to_datetime(Test_Data_1['disbursal_date'])\n",
    "Test_Data_1['default_date'] = pd.to_datetime(Test_Data_1['default_date'])\n",
    "\n",
    "# Calculate the number of months between 'disbursal_date' and 'default_date'\n",
    "Test_Data_1['Regular_Payment_Period'] = (Test_Data_1['default_date'] - Test_Data_1['disbursal_date']).dt.days / 30.4375\n",
    "\n",
    "# Round off the values to two decimal places\n",
    "Test_Data_1['Regular_Payment_Period'] = Test_Data_1['Regular_Payment_Period'].round(2)\n",
    "# Convert 'tenure_years' column to months\n",
    "Test_Data_1['tenure_months'] = Test_Data_1['tenure_years'] * 12\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame with the converted 'Regular_Payment_Period' & Tenure in months column\n",
    "Test_Data_1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e7eee-b7c0-4fb2-ae18-fc930f24a63e",
   "metadata": {},
   "source": [
    "#### Removing all Date columns as those wont be useful for creating final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd11a4-195a-40d4-aa28-5252eb7ebef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns from Test_Data and assign the result back to Test_Data\n",
    "# List of columns to drop\n",
    "drop_cols = ['disbursal_date', 'default_date', 'date', 'customer_address', 'customer_name','tenure_years']\n",
    "Test_Data = Test_Data_1.drop(columns=drop_cols)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(Test_Data.shape)\n",
    "Test_Data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3be149-634b-4021-a743-d9440521f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac028974-b3e7-4572-94b0-71d74b4a2e4e",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8e4b6-8a12-4377-8346-92095742eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*Test_Data.isnull().mean(),2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4ce40-deed-4d51-aa1d-9b65337c13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in 'repayment_amount' and 'balance_amount' columns with 0\n",
    "Test_Data['repayment_amount'].fillna(0, inplace=True)\n",
    "Test_Data['balance_amount'].fillna(0, inplace=True)\n",
    "\n",
    "round(100*Test_Data.isnull().mean(),2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3fb80a-d9fd-4fe7-8835-310eba3393d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heads of dataset\n",
    "Test_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf077e6-f844-4f94-91c4-9bf7a8e30a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop circle_id column\n",
    "Test_Data = Test_Data.drop('loan_acc_num', axis=1)\n",
    "Test_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88782c7e-c6d7-44eb-a3e8-889e2cc0e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the value_counts of loan_type column\n",
    "Test_Data['loan_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fbbf0-b30f-4671-bddb-54977530dfa6",
   "metadata": {},
   "source": [
    "### Creating LGD column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d84535-4cab-4c5d-9596-b401bde690cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Loss Given Default (LGD)\n",
    "Test_Data['LGD'] = Test_Data['loan_amount'] - ((Test_Data['collateral_value'] + Test_Data['repayment_amount']))\n",
    "\n",
    "Test_Data['LGD'] = Test_Data['LGD']/Test_Data['loan_amount']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "Test_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d52945-47c1-4999-9e42-29e75743ae64",
   "metadata": {},
   "source": [
    "### As we can see all loan types are equally contributing for the overall distribution,hence, these categorical input variable will have mutli colinearity in model building, Hence deleting this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006432a-e0f7-4a1e-b24d-54f6a061ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data = Test_Data.drop([\"loan_type\"], axis=1)\n",
    "print(Test_Data.shape)\n",
    "Test_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21670a67-e082-47cb-b2a4-95bd18f545a6",
   "metadata": {},
   "source": [
    "### Rescaling the Features\n",
    "### We will use MinMax scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486517c-9df7-4506-97f8-7b7a0eee9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "Test_Data_scaled = scaler.fit_transform(Test_Data)\n",
    "Test_Data_scaled = pd.DataFrame(Test_Data_scaled, columns=Test_Data.columns)\n",
    "print(Test_Data_scaled.shape)\n",
    "Test_Data_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a25d1-e06f-4ab8-9df9-19dbe5183a84",
   "metadata": {},
   "source": [
    "### Modeling the Test_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfcfb5-4bc0-4e94-87f0-0ce1bcbcea20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Test_Data_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafa55e-aaa1-4d8f-8579-3f3d1b36327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = Test_Data_scaled.pop('LGD')\n",
    "X_test = Test_Data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69acc35a-e5e5-40d5-b8a1-6a19518e12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f77536-7b93-4e8e-8b0c-3571702d4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f809c-f345-421d-bf34-935766818811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant variable to Test Dataset\n",
    "import statsmodels.api as sm\n",
    "X_test_sm=sm.add_constant(X_test)\n",
    "X_test_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc19e00-87fc-4528-a368-3303b3852eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_test = X_train_sm.columns\n",
    "\n",
    "X_test_sm = X_test_sm[selected_features_test]\n",
    "X_test_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8070bc-bbbc-4816-b824-ea98d8a2ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable\n",
    "y_test_pred_2 = res3.predict(X_test_sm)\n",
    "y_test_pred_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df4ca7-ce52-4ed1-829b-822af15d43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_test - y_test_pred_2), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 10)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 10)                         # X-label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74bdab-0794-440f-a084-e542db3048e5",
   "metadata": {},
   "source": [
    "#### Adjusted R^2 Value for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d6d98-e63f-4be9-9093-bc711b9680c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_test_sm.shape[0]\n",
    "# Number of features (predictors, p) is the shape along axis 1\n",
    "p = X_test_sm.shape[1]\n",
    "\n",
    "# We find the Adjusted R-squared using the formula\n",
    "\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "adjusted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f631bbb-abdc-42d3-b833-21f492ea6082",
   "metadata": {},
   "source": [
    "## Model Evaluation of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a51d8-1546-4473-adab-d43fe95b5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread.\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test,y_test_pred_2)\n",
    "fig.suptitle('y_test vs y_test_pred_1', fontsize=20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize=10)                          # X-label\n",
    "plt.ylabel('y_pred', fontsize=10)                          # Y-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00edc7-204f-4f9f-8e69-6c591ec4df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the fit on the test data\n",
    "# plotting a Regression plot\n",
    "\n",
    "plt.figure()\n",
    "sns.regplot(x=y_test, y=y_test_pred_2, ci=68, fit_reg=True,scatter_kws={\"color\": \"green\"}, line_kws={\"color\": \"red\"})\n",
    "plt.title('y_test vs y_pred', fontsize=20)\n",
    "plt.xlabel('y_test', fontsize=18)\n",
    "plt.ylabel('y_pred', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9acdccd-68ad-4d4f-b321-461321f9d0a3",
   "metadata": {},
   "source": [
    "### Plotting Loan Account number Distribution Plot wrt Predicted Loss Given Default (LGD) Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c74324-d043-4f75-89e2-2c73db053f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Series to 'LGD'\n",
    "y_test_pred_2 = y_test_pred_2.rename('LGD')\n",
    "\n",
    "# Concatenate the loan account numbers and LGD values along the column axis\n",
    "matched_data_test = pd.concat([Test_Data_1['loan_acc_num'], y_test_pred_2], axis=1)\n",
    "\n",
    "# Display the matched data\n",
    "matched_data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b84336-7a7e-4ee5-b451-75d5b71c10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the style of the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot the distribution of LGD values\n",
    "plt.figure(figsize=(20, 8))\n",
    "ax = sns.histplot(matched_data_test['LGD'], kde=True, color='red')\n",
    "\n",
    "# Add data labels for frequency\n",
    "for rect in ax.patches:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 4, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Distribution of LGD Values')\n",
    "plt.xlabel('LGD')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803ab71-6b70-4310-904e-77aa4d88874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(res3.params, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b64be1-bf12-450e-a788-20d2fd0c4f83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c7853d-d734-4689-9cc3-447010a1ce25",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
